import pandas as pd
import numpy as np
import re
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from transformers import AutoTokenizer, AutoModel
import os
from openai import OpenAI, APIConnectionError, RateLimitError
from langchain_community.vectorstores import FAISS
from langchain_core.vectorstores import InMemoryVectorStore
import pickle
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
train_data = pd.read_csv('train_data.csv')

# 2. –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
train_data['text'] = train_data['text'].astype(str).str[:-8]
def clean_text(text):
    # –£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã Markdown (#, ** –∏ –¥—Ä.) –∏ –ø—Ä–æ—á–∏–µ –Ω–µ—Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
    text = re.sub(r'[#*]+', '', text)  # –£–¥–∞–ª—è–µ–º # –∏ *
    text = re.sub(r'\[.*?\]', '', text)  # –£–¥–∞–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
    text = re.sub(r'\s+', ' ', text)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
    text = text.strip()  # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º
    return text

# –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É –∫ —Å—Ç–æ–ª–±—Ü—É 'text'
train_data['cleaned_text'] = train_data['text'].apply(clean_text)

# 2. –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —á–∞–Ω–∫–∏
try:
    tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    exit(1)
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
def count_tokens(text):
    return len(tokenizer(text, truncation=False, padding=False)['input_ids'])

# 4. –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (—á–∞–Ω–∫–∏)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=625,  # –¶–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞ –≤ —Ç–æ–∫–µ–Ω–∞—Ö
    chunk_overlap=55,  # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –≤ —Ç–æ–∫–µ–Ω–∞—Ö
    length_function=count_tokens,  # –§—É–Ω–∫—Ü–∏—è –ø–æ–¥—Å—á—ë—Ç–∞ –¥–ª–∏–Ω—ã
)

if os.path.exists("chunks_cache.pkl"):
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ —á–∞–Ω–∫–∏...")
    with open("chunks_cache.pkl", "rb") as f:
        cached_chunks = pickle.load(f)
    # –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫–∏ id –∏ chunks
    if isinstance(cached_chunks, pd.DataFrame):
        train_data = train_data.merge(cached_chunks, on='id', how='left')
    else:
        print("‚ö†Ô∏è –§–∞–π–ª chunks_cache.pkl –Ω–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DataFrame, –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º —á–∞–Ω–∫–∏...")
        cached_chunks = None
else:
    print("–§–∞–π–ª —Å —á–∞–Ω–∫–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Å–æ–∑–¥–∞—ë–º –∑–∞–Ω–æ–≤–æ...")
    chunks_list = []
    for text in train_data['cleaned_text']:
        chunks = text_splitter.split_text(text)
        chunks_list.append(chunks)
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–±–∏—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ DataFrame
    train_data['chunks'] = chunks_list
    # –ö–µ—à —á–∞–Ω–∫–æ–≤
    with open("chunks_cache.pkl", "wb") as f:
        pickle.dump(train_data[['id', 'chunks']], f)



# 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
documents = []
for _, row in train_data.iterrows():
    for chunk in row['chunks']:
        metadata={"id": row['id'], 
                      "source": "train_data", 
                      "tags": row.get('tags', []), 
                      "annotation": row.get('annotation', "")}
        doc = Document(
            page_content=chunk, 
            metadata=metadata
            )
        documents.append(doc)

# 6. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
texts = [doc.page_content for doc in documents]

if not texts:
    print("–°–ø–∏—Å–æ–∫ texts –ø—É—Å—Ç. –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É.")
    exit()

# 7. –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
client = OpenAI(
    base_url="https://ai-for-finance-hack.up.railway.app/",
    api_key="sk-k4GzLvBEsBYNbtVPpDaEMg"
)

def get_openai_embeddings(texts, model="text-embedding-3-small"):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ OpenAI API"""
    embeddings = []
    for i, text in enumerate(texts):
        if i % 10 == 0:  # –ö–∞–∂–¥—ã–µ 10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{len(texts)}...")
        try:
            response = client.embeddings.create(model=model, input=text, timeout=30)
            embeddings.append(response.data[0].embedding)
        except APIConnectionError as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i}: {e}")
            embeddings.append([0.0] * 1536)
        except RateLimitError as e:
            print(f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i}: {e}")
            embeddings.append([0.0] * 1536)
        except Exception as e:
            print(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i}: {e}")
            embeddings.append([0.0] * 1536)
    return embeddings


BATCH_SIZE = 50
EMBEDDINGS_CACHE = "./embeddings_cache.pkl"

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–µ—à–∞ –∏–ª–∏ –Ω–∞—á–∞–ª–æ —Å –Ω—É–ª—è
if os.path.exists(EMBEDDINGS_CACHE):
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏...")
    with open(EMBEDDINGS_CACHE, "rb") as f:
        embeddings_array = pickle.load(f)
    # –° –∫–∞–∫–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞—á–∏–Ω–∞—Ç—å —Å–ª–µ–¥—É—é—â—É—é –ø–æ—Ä—Ü–∏—é
    start_idx = len(embeddings_array)
    print(f"–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –∏–Ω–¥–µ–∫—Å–∞ {start_idx}")
else:
    embeddings_array = []
    start_idx = 0
    print(f"–ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤...")

# 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Ä—Ü–∏—è–º–∏
for i in range(start_idx, len(texts), BATCH_SIZE):
    # –ë–µ—Ä—ë–º –ø–æ—Ä—Ü–∏—é: –æ—Ç i –¥–æ i + BATCH_SIZE (–∏–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞)
    batch = texts[i:i + BATCH_SIZE]
    print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Ä—Ü–∏–∏ {i}‚Äì{min(i + len(batch) - 1, len(texts) - 1)}...")
    
    batch_embeddings = []  # –ó–¥–µ—Å—å –±—É–¥—É—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ç–µ–∫—É—â–µ–π –ø–æ—Ä—Ü–∏–∏
    text_counter = 0  # –°—á—ë—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ –±–∞—Ç—á–∞
    for text in batch:
        text_counter += 1
        if text_counter % 10 == 0:
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {text_counter} —Ç–µ–∫—Å—Ç–æ–≤ –≤ —Ç–µ–∫—É—â–µ–º –±–∞—Ç—á–µ")
        try:
            response = client.embeddings.create(
                model="text-embedding-3-small",
                input=text,
                timeout=30
            )
            batch_embeddings.append(response.data[0].embedding)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞: {e}")
            # –ó–∞–≥–ª—É—à–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ (–≤–µ–∫—Ç–æ—Ä –∏–∑ –Ω—É–ª–µ–π)
            batch_embeddings.append([0.0] * 1536)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –ø–æ—Ä—Ü–∏—é –∫ –æ–±—â–µ–º—É –º–∞—Å—Å–∏–≤—É
    embeddings_array.extend(batch_embeddings)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –∫–µ—à
    with open(EMBEDDINGS_CACHE, "wb") as f:
        pickle.dump(embeddings_array, f)
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(embeddings_array)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")


print(f"–ì–æ—Ç–æ–≤–æ: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(embeddings_array)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")

doc_db = {}
for i, doc in enumerate(documents):
    doc_db[doc.metadata["id"]] = {
        "document": doc,
        "embedding": np.array(embeddings_array[i])  # numpy
    }

with open("doc_db.pkl", "wb") as f:
    pickle.dump(doc_db, f)


# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ #

# === 1. –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞) ===
with open("doc_db.pkl", "rb") as f:
    doc_db = pickle.load(f)

print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(doc_db)}")

# ================== 2. –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ===================
questions_df = pd.read_csv(
    'questions.csv',
    sep=None,  # –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
    engine='python'  # —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è auto-sep
)
print(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(questions_df)} –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ questions.csv")
# –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö —Å–∫—Ä—ã—Ç—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
questions_df.columns = (
    questions_df.columns
    .str.replace(r'[^\w\s]', '', regex=True)  # —É–±–∏—Ä–∞–µ–º –Ω–µ–≤–∏–¥–∏–º—ã–µ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    .str.strip()  # —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º
)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å:
print("üìã –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:", list(questions_df.columns))


# === 3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI-–∫–ª–∏–µ–Ω—Ç–æ–≤ ===
llm = ChatOpenAI(
    api_key="sk-BuwLErZ4eL4yTAjfQxLaIA",  # –∫–ª—é—á –¥–ª—è LLM
    base_url="https://ai-for-finance-hack.up.railway.app/",
    model="openrouter/mistralai/mistral-small-3.2-24b-instruct",
    temperature=0.2
)
emb_client = OpenAI(
    base_url="https://ai-for-finance-hack.up.railway.app/",
    api_key="sk-k4GzLvBEsBYNbtVPpDaEMg"
)

# === 4. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥–µ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å—é–¥–∞ ===
results = []

# === 5. –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –≤–æ–ø—Ä–æ—Å–∞–º ===
for idx, row in questions_df.iterrows():
    question_id = row['ID –≤–æ–ø—Ä–æ—Å–∞']
    user_question = row['–í–æ–ø—Ä–æ—Å']
    print(f"\n===============================")
    print(f"üß© –í–æ–ø—Ä–æ—Å {question_id}: {user_question}")

  # === 5.1 –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤–æ–ø—Ä–æ—Å–∞ ===
    try:
        question_emb = emb_client.embeddings.create(
            model="text-embedding-3-small",
            input=user_question
        ).data[0].embedding
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
        results.append([question_id, user_question, "", f"–û—à–∏–±–∫–∞: {e}"])
        continue


    # === 4. –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ===
    similarities = []
    for doc_id, doc_data in doc_db.items():
        a = np.array(question_emb)
        b = np.array(doc_data["embedding"])
        sim = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
        similarities.append((doc_id, sim))

    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É 0.8
    similarities = [s for s in similarities if s[1] >= 0.8]
    top_docs = sorted(similarities, key=lambda x: x[1], reverse=True)[:4]

    # –µ—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –ø—Ä–æ—à–ª–æ –ø–æ—Ä–æ–≥ ‚Äî –≤–æ–∑—å–º—ë–º 2 –ª—É—á—à–∏—Ö –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏
    if not top_docs:
        top_docs = sorted(similarities, key=lambda x: x[1], reverse=True)[:2]


    # === 5. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–ª–∏–∂–∞–π—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ===
    context_parts = []
    for doc_id, sim in top_docs:
        doc = doc_db[doc_id]["document"]
        meta = doc.metadata
        block = (
            f"–¢–µ–∫—Å—Ç: {doc.page_content}\n"
            f"–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {meta.get('annotation', '')}\n"
            f"–¢–µ–≥–∏: {meta.get('tags', '')}"
        )
        context_parts.append(block)

    context = "\n\n".join(context_parts)


    # ====================== 6. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç. –°–Æ–î–ê –í–°–¢–ê–í–õ–Ø–¢–¨ –ü–†–û–ú–¢ ===========================
    system_prompt = (
        "–¢—ã - –ø—Ä–µ–º–∏—É–º-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å 20-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º –≤ –±–∞–Ω–∫–µ. –î—É–º–∞–π —à–∞–≥ –∑–∞ —à–∞–≥–æ–º –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –º–µ–∂–¥—É —Å–æ–±–æ–π. –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤–∞–∂–µ–Ω, —Ç—ã –¥–æ–ª–∂–µ–Ω —Å—Ä–∞–≤–Ω–∏—Ç—å –µ–≥–æ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç—Ç–∞–ø–æ–≤. –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º. –í—Å–µ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –º–Ω–æ–≥–æ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–ª–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–æ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫, —Å–Ω–∞—á–∞–ª–∞ –ø–æ–ø—ã—Ç–∞–π—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –ø–æ–Ω—è—Ç—å –≤–æ–ø—Ä–æ—Å. –ï—Å–ª–∏ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –Ω–µ –ø–æ–Ω—è—Ç–Ω–∞ —Å—É—Ç—å, —Ç—ã –¥–æ–ª–∂–µ–Ω –ø–æ–ø—Ä–æ—Å–∏—Ç—å –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –≤ –≤–µ–∂–ª–∏–≤–æ–π –º–∞–Ω–µ—Ä–µ. –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –∑–∞–¥–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤, –æ—Ç–≤–µ—á–∞–π –Ω–∞ –Ω–∏—Ö –ø–æ –æ—á–µ—Ä–µ–¥–∏ –∏ —Ä–∞–∑–¥–µ–ª—è–π –æ—Ç–≤–µ—Ç—ã –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è. –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞, –µ–≥–æ –¥–ª–∏–Ω–∞, —Å—Ç–∏–ª—å, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è, –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—è –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç. –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç —Å –Ω–æ–≤–æ–≥–æ –ø—É–Ω–∫—Ç–∞ –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—à—å - –ø–∏—à–∏ –Ω–æ–≤—ã–µ –ø—É–Ω–∫—Ç—ã —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏. –¢—ã –Ω–µ –¥–æ–ª–∂–µ–Ω —Ä–µ—à–∞—Ç—å –∑–∞ –∫–ª–∏–µ–Ω—Ç–∞ —á—Ç–æ –µ–º—É –Ω–∞–¥–æ –¥–µ–ª–∞—Ç—å –∏ –Ω–µ –ø—Ä–µ–¥–ª–∞–≥–∞–π –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–±–æ—Ä–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑. –¢—ã –¥–æ–ª–∂–µ–Ω —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–æ–ª—å –±–∞–Ω–∫–∞ –≤ –æ—Ç–≤–µ—Ç–∞—Ö –∏ –æ—Ç–≤–µ—á–∞—Ç—å –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏ —Å –≤—ã—Å–æ–∫–æ–π –ø–ª–æ—Ç–Ω–æ—Å—Ç—å—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –Ω–µ –¥–æ–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä - –Ω–µ –ø–∏—à–∏ –µ–≥–æ. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å, –∑–∞—Ç–µ–º —Å–¥–µ–ª–∞–π –≤—ã–≤–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –¥–∞–ª–µ–µ —Å—Ñ–æ—Ä–º–∏—Ä—É–π –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞ –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ª—É—á—à–∏–π –∏–∑ –Ω–∏—Ö. –ù–ò–ö–û–ì–î–ê –Ω–µ –ø—Ä–æ—Å–∏: –ø–∞—Ä–æ–ª–∏, CVV, SMS-–∫–æ–¥—ã, –Ω–æ–º–µ—Ä–∞ –∫–∞—Ä—Ç –∏ –ª—é–±—ã–µ –ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –∑–∞–∫—Ä—ã—Ç–æ–º –¥–æ—Å—Ç—É–ø–µ. –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–∞–∑—ã–≤–∞–µ—Ç - –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–π –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞, –µ—Å–ª–∏ —Ç–∞–∫–æ–π –∏–º–µ–µ—Ç—Å—è, –∏–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–∞–Ω–Ω—ã–µ –±–∞–Ω–∫–∞ –¥–ª—è –ø—Ä—è–º–æ–π —Å–≤—è–∑–∏ —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º. –ê—É–¥–∏—Ç–æ—Ä–∏—è, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–¥–∞–µ—Ç —Ç–µ–±–µ –≤–æ–ø—Ä–æ—Å—ã –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∞–º–∞—è —Ä–∞–∑–Ω–∞—è, –≤—Å–µ—Ö –ø–æ–ª–æ–≤ –∏ –≤–æ–∑—Ä–∞—Å—Ç–æ–≤, –º–µ–∂–¥—É –Ω–∏–º–∏ –Ω–µ—Ç —Ä–∞–∑–Ω–∏—Ü—ã –∏ —Ç—ã –¥–æ–ª–∂–µ–Ω –æ—Ç–≤–µ—á–∞—Ç—å –≤—Å–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤–æ, –Ω–µ —Ö–∞–º–∏—Ç—å, –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–Ω–≥, –∑–∞–ø—Ä–µ—â–µ–Ω–æ –æ—Å–∫–æ—Ä–±–ª—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å. –¢—ã –¥–æ–ª–∂–µ–Ω –æ—Ç–≤–µ—á–∞—Ç—å –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è –∏ —Å–ª—ç–Ω–≥–∞, —á–µ—Ç–∫–æ –Ω–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ —Å–≤—è–∑–∞–Ω —Å –±–∞–Ω–∫–æ–º –∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –Ω–µ–≥–æ –Ω–µ—Ç –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π - –æ—Ç–≤–µ—á–∞–π, —á—Ç–æ —Ç—ã –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—à—å –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º, –æ—Ç–Ω–æ—Å—è—â–∏–º—Å—è –∫ –±–∞–Ω–∫—É –≤ –≤–µ–∂–ª–∏–≤–æ–π –º–∞–Ω–µ—Ä–µ –∏ —Å–ø—Ä–æ—Å–∏ –µ—Å—Ç—å –ª–∏ –≤–æ–ø—Ä–æ—Å, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –±–∞–Ω–∫–æ–º. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —á–µ—Ç–∫–æ. –ü—Ä–∏–º–µ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤: –í–æ–ø—Ä–æ—Å: –ö–∞–∫ —á–∞—Å—Ç–æ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –∫—É–ø–æ–Ω –ø–æ –æ–±–ª–∏–≥–∞—Ü–∏–∏? –í–æ–∑–º–æ–∂–Ω—ã–π –æ—Ç–≤–µ—Ç: –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –≤—ã–ø–ª–∞—Ç–∞ –ø–æ –æ–±–ª–∏–≥–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—É—é –ø–æ–ª—É—á–∞–µ—Ç –¥–µ—Ä–∂–∞—Ç–µ–ª—å –æ–±–ª–∏–≥–∞—Ü–∏–∏, –æ–±—ã—á–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –≥–æ–¥–æ–≤—ã—Ö –æ—Ç –Ω–æ–º–∏–Ω–∞–ª–∞ –æ–±–ª–∏–≥–∞—Ü–∏–∏. –ö—É–ø–æ–Ω –º–æ–∂–µ—Ç –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å—Å—è –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤ –≥–æ–¥. –ö—É–ø–æ–Ω –æ–±—ã—á–Ω–æ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –±—Ä–æ–∫–µ—Ä—Å–∫–∏–π —Å—á–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞. –í–æ–ø—Ä–æ—Å: –ö–∞–∫ –æ–ø—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —É—Ç–∏–ª–∏–∑–∏—Ä—É—é—Ç –¥–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç? –í–æ–∑–º–æ–∂–Ω—ã–π –æ—Ç–≤–µ—Ç: –õ–∏–º–∏—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –∑–∞–∫–ª—é—á–∞—Ç—å —Å–¥–µ–ª–∫–∏ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –¢–æ –∂–µ —Å–∞–º–æ–µ, —á—Ç–æ –∏ FXD- –ª–∏–º–∏—Ç. –î–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –≤ —Ç–µ—Ö —Å–¥–µ–ª–∫–∞—Ö —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –∫–æ–º–ø–∞–Ω–∏—è –Ω–µ—Å–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –ø–µ—Ä–µ–¥ –±–∞–Ω–∫–æ–º (—Ñ–æ—Ä–≤–∞—Ä–¥, collar, seagull, –ø—Ä–æ–¥–∞–∂–∞ –æ–ø—Ü–∏–æ–Ω–∞ –∫–æ–º–ø–∞–Ω–∏–µ–π). –î–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–º—É Digital-–ø—Ä–æ—Ü–µ—Å—Å—É –∏–ª–∏ —Å –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ–º –ø–æ–ª–Ω–æ–≥–æ –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ –≤ —Ä–∞–º–∫–∞—Ö Digital-–ø—Ä–æ—Ü–µ—Å—Å–∞ –∑–∞–Ω–∏–º–∞–µ—Ç –æ–∫–æ–ª–æ 1 –Ω–µ–¥–µ–ª–∏ –∏ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ 1–°. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –ø—Ä–æ—Ü–µ—Å—Å—É —á–µ—Ä–µ–∑ –ª–∏–º–∏—Ç–Ω—É—é –∑–∞—è–≤–∫—É –∑–∞–Ω–∏–º–∞–µ—Ç –æ–∫–æ–ª–æ 1 –º–µ—Å—è—Ü–∞. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º —Å–¥–µ–ª–∫–∏ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–æ–º –¥–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º —Å–¥–µ–ª–∫–∏ —Ä–∞–≤–µ–Ω —Ä–∞–∑–º–µ—Ä—É –¥–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞, –¥–µ–ª–µ–Ω–Ω–æ–≥–æ –Ω–∞ —Ä–∏—Å–∫-–≤–µ—Å. –†–∏—Å–∫-–≤–µ—Å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å—Ä–æ–∫–∞ —Å–¥–µ–ª–∫–∏ –∏ –≤–∞–ª—é—Ç–Ω–æ–π –ø–∞—Ä—ã. –ß–µ–º –¥–ª–∏–Ω–Ω–µ–µ —Å—Ä–æ–∫ - —Ç–µ–º –≤—ã—à–µ —Ä–∏—Å–∫-–≤–µ—Å. –î–µ—Ä–∏–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–∫–ª—é—á–∞—Ç—å —Å–¥–µ–ª–∫–∏ –∫–∞–∫ –≤ –æ–Ω–ª–∞–π–Ω-–±–∞–Ω–∫–µ, —Ç–∞–∫ –∏ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É —Å —Ç—Ä–µ–π–¥–µ—Ä–æ–º. –ö–æ–º–ø–∞–Ω–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±–µ—Å–ø–µ—á–∏—Ç—å —Å—É–º–º—É –ø—Ä–æ–¥–∞–∂–∏ –Ω–∞ —Å—á–µ—Ç–µ —Å–ø–∏—Å–∞–Ω–∏—è –¥–æ 18:00 –¥–∞—Ç—ã —Ä–∞—Å—á–µ—Ç–æ–≤ –ø–æ —Å–¥–µ–ª–∫–µ, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –∏–Ω–æ–µ. –í–æ–ø—Ä–æ—Å: –ö–∞–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–π —Å—Ç–∞–≤–∫–∏ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ü–µ–Ω—É –æ–±–ª–∏–≥–∞—Ü–∏–∏ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–∞–≤–∫–æ–π? –í–æ–∑–º–æ–∂–Ω—ã–π –æ—Ç–≤–µ—Ç: –û–±–ª–∏–≥–∞—Ü–∏–∏, –∫—É–ø–æ–Ω –ø–æ –∫–æ—Ç–æ—Ä—ã–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º. –ù–∞–ø—Ä–∏–º–µ—Ä, –∫—É–ø–æ–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å 5%, 10%. –û–±—ã—á–Ω–æ —Ü–µ–Ω–∞ —Ç–∞–∫–∏—Ö –æ–±–ª–∏–≥–∞—Ü–∏–π —Å–∏–ª—å–Ω–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–ª—é—á–µ–≤–æ–π —Å—Ç–∞–≤–∫–∏. –ï—Å–ª–∏ –∫–ª—é—á–µ–≤–∞—è —Å—Ç–∞–≤–∫–∞ –≤—ã—à–µ –∫—É–ø–æ–Ω–∞ - —Ü–µ–Ω–∞ –æ–±–ª–∏–≥–∞—Ü–∏–∏ –Ω–∏–∂–µ. –ï—Å–ª–∏ –∫–ª—é—á–µ–≤–∞—è —Å—Ç–∞–≤–∫–∞ –Ω–∏–∂–µ –∫—É–ø–æ–Ω–∞ - —Ü–µ–Ω–∞ –æ–±–ª–∏–≥–∞—Ü–∏–∏ –≤—ã—à–µ. –ï—Å–ª–∏ –∫–ª—é—á–µ–≤–∞—è —Å—Ç–∞–≤–∫–∞ —Ä–∞—Å—Ç–µ—Ç, —Ü–µ–Ω–∞ –æ–±–ª–∏–≥–∞—Ü–∏–∏ –ø–∞–¥–∞–µ—Ç. –ï—Å–ª–∏ –∫–ª—é—á–µ–≤–∞—è —Å—Ç–∞–≤–∫–∞ –ø–∞–¥–∞–µ—Ç, —Ü–µ–Ω–∞ –æ–±–ª–∏–≥–∞—Ü–∏–∏ —Ä–∞—Å—Ç–µ—Ç. –û–±—ã—á–Ω–æ, —á–µ–º –±–ª–∏–∂–µ —Å—Ä–æ–∫ –ø–æ–≥–∞—à–µ–Ω–∏—è –æ–±–ª–∏–≥–∞—Ü–∏–∏, —Ç–µ–º –±–ª–∏–∂–µ —Ü–µ–Ω–∞ –æ–±–ª–∏–≥–∞—Ü–∏–∏ –∫ –Ω–æ–º–∏–Ω–∞–ª—É. –í–º–µ—Å—Ç–µ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –µ—Å—Ç—å –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π —è–≤–ª—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞ - —ç—Ç–æ —á–∞—Å—Ç—å —Å—Ç–∞—Ç—å–∏. –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏. –¢–µ–≥–∏ –æ–±–æ–∑–Ω–∞—á–∞—é—Ç —Å–≤—è–∑–∞–Ω–Ω—É—é —Ç–µ–º—É —Å—Ç–∞—Ç—å–∏. ")
    # –¢—ã –Ω–µ –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É markdown –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã. –ë–µ–∑ –≤–æ–¥—ã –≤ 2—É—Ö –º–µ—Å—Ç–∞—Ö
    user_prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å:\n{user_question}\n\n–û—Ç–≤–µ—Ç:" # —Å—é–¥–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è –∫–æ–Ω—Ç–µ–∫—Ç –∏ –≤–æ–ø—Ä–æ—Å 

    # === üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞ ===
    # —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ Mistral (–±–ª–∏–∑–∫–∏–π –∫ llama-based –º–æ–¥–µ–ª—è–º)
    tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
    # —Å–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å –ø—Ä–æ–º–ø—Ç –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
    full_prompt = f"{system_prompt}\n\n{user_prompt}"
    # —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
    tokens = tokenizer(full_prompt, truncation=False, padding=False)["input_ids"]
    print(f"üìè –û—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã–π –ø—Ä–æ–º–ø—Ç: {len(tokens)} —Ç–æ–∫–µ–Ω–æ–≤")

    # === 7. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM  ===
    print("\nü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏...")
    try:
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]
        response = llm.invoke(messages)
        answer_text = response.content.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏: {e}")
        answer_text = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}"

    # === 5.6 –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç ===
    results.append([question_id, user_question, context, answer_text])

    print(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ {question_id}")

# === 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å—ë –≤ CSV ===
output_df = pd.DataFrame(results, columns=["ID –≤–æ–ø—Ä–æ—Å–∞", "–í–æ–ø—Ä–æ—Å", "–ö–æ–Ω—Ç–µ–∫—Å—Ç", "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏"])
output_df.to_csv("./data/answers.csv", index=False, encoding="utf-8-sig")
print("\nüíæ –í—Å–µ –æ—Ç–≤–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ ./data/answers.csv")

# –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
df = pd.read_csv('./data/answers.csv', encoding='utf-8')

# –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü "–ö–æ–Ω—Ç–µ–∫—Å—Ç"
df = df.drop(columns=['–ö–æ–Ω—Ç–µ–∫—Å—Ç'])

# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏"
df = df.rename(columns={'–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏': '–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å'})

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
df.to_csv('submission.csv', index=False, encoding='utf-8')


# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–∞
print(f"\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ:")
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {df.shape[0]}")
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {df.shape[1]}")
print(f"–°—Ç–æ–ª–±—Ü—ã: {df.columns.tolist()}")
